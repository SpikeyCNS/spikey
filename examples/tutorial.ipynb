{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spikey Tutorial\n",
    "\n",
    "A narrow introduction to Spikey with examples.\n",
    "\n",
    "Table of Contents\n",
    "---\n",
    "1. Installation\n",
    "2. Pieces of a Spiking Neural Network\n",
    "3. Creating a Spiking Neural Network\n",
    "4. Games\n",
    "5. Training Loops\n",
    "7. Moving Forward\n",
    "\n",
    "```none\n",
    "----------  -----------  ---------  -----\n",
    "| Neuron |  | Synapse |  | Input |  | ...\n",
    "----------  -----------  ---------  -----\n",
    "       \\         |         /\n",
    "         \\       |       /\n",
    "--------   -------------\n",
    "| Game |   |  Network  |\n",
    "--------   -------------\n",
    "   |            /\n",
    "   |           /\n",
    "-----------------\n",
    "| Training Loop |\n",
    "-----------------\n",
    "        |\n",
    "----------------------\n",
    "| Aggregate Analysis |\n",
    "----------------------\n",
    "    ^       |\n",
    "    L_______|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First open a terminal in the root directory of your cloned Spikey repo.\n",
    "\n",
    "You should see something like,\n",
    "```bash\n",
    ".../username/spikey>\n",
    "```\n",
    "\n",
    "If not change terminals working directory to the spikey repo via,\n",
    "```bash\n",
    "cd <path to your cloned spikey repo>\n",
    "\n",
    "# eg,\n",
    "cd /home/user/spikey\n",
    "```\n",
    "\n",
    "Install all necessary dependencies,\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Then since Spikey is not yet on pypi, install it locally via\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Spikey only needs to be reinstalled if you re-clone the repo or move it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After installation, restart this notebook and this import should work.\n",
    "import spikey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pieces of a spiking neural network\n",
    "\n",
    "Spiking neural networks are complex systems capable of learning in a similar way to the human brain.\n",
    "They are composed of many unique parts: neurons, synapses, ... all of which are individually simple, \n",
    "yet can cooperate to achieve the ability to understand the environment they operate in.\n",
    "This is an emergent process.\n",
    "\n",
    "In this simulator we have individual objects for all spiking network parts.\n",
    "There are multiple pre-built versions of each, but you may template any of them to create your own versions.\n",
    "\n",
    "Luckily the Network object exists within Spikey to manage all of these parts for you, but we will kick of the tutorial by demoing them individually.\n",
    "```\n",
    "Neuron: Standard neuron behavior.\n",
    "Synapse: Synaptic learning rule implementation.\n",
    "Weight: Datastructure to generate and manage network topology, connects individual inputs and neurons together.\n",
    "Input: Neuron without inputs that serve to encode sensory information from the environment.\n",
    "Readout: Function to translate the network's reaction into an action within the environment.\n",
    "Rewarder(RL networks only): Determine how much reward the network deserves for its response.\n",
    "```\n",
    "```none\n",
    "----------  -----------  ---------  -----\n",
    "| Neuron |  | Synapse |  | Input |  | ...\n",
    "----------  -----------  ---------  -----\n",
    "       \\         |         /\n",
    "         \\       |       /\n",
    "           -------------\n",
    "           |  Network  |\n",
    "           -------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "from spikey import Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"n_inputs\": \"[<class 'int'>] Number input neurons, separate from body.\",\n",
       " \"magnitude\": \"[(<class 'float'>, <class 'int'>)] Multiplier to each 0, 1 spike value.\",\n",
       " \"input_firing_steps\": \"[<class 'int'>, default=-1] Number of network steps to fire for, -1 if all.\",\n",
       " \"input_pct_inhibitory\": \"[(<class 'float'>, <class 'int'>), default=0] Pct of inputs that are inhibitory\",\n",
       " \"state_spike_map\": \"[(<class 'dict'>, <class 'numpy.ndarray'>, <class 'object'>)] dict[tuple]->ndarray[processing_time, n_inputs, dtype=bool] State to fires map..\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each piece of the network has many parameters that need to be set.\n",
    "# All parameters and their descriptions are listed in the parts NECESSARY_KEYS.\n",
    "input_type = spikey.input.StaticMap\n",
    "input_type.NECESSARY_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys can be configured by a dictionary to be passed into the constructor\n",
    "input_config = {\n",
    "    'n_inputs': 2,\n",
    "    'magnitude': 1,\n",
    "    'firing_steps': -1,\n",
    "    'input_pct_inhibitory': 0,\n",
    "    'state_spike_map': {0: [0, 0], 1: [0, 1], 2: [1, 0], 3: [1, 1]},\n",
    "}\n",
    "input = input_type(**input_config)\n",
    "input.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell the input about the environment state\n",
    "input.update(1)\n",
    "\n",
    "# Input fire according to state\n",
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"magnitude\": \"[(<class 'float'>, <class 'int'>)] Magnitude of spike.\",\n",
       " \"n_neurons\": \"[<class 'int'>] Number of neurons in the network.\",\n",
       " \"firing_threshold\": \"[(<class 'float'>, <class 'int'>)] Neuron voltage threshold to fire.\",\n",
       " \"neuron_pct_inhibitory\": \"[(<class 'float'>, <class 'int'>), default=0] [0, 1] Percentage of inhibitory neurons.\",\n",
       " \"potential_decay\": \"[(<class 'float'>, <class 'int'>)] [0, 1] Percentage voltage loss on each tick.\",\n",
       " \"prob_rand_fire\": \"[(<class 'float'>, <class 'int'>), default=0]  [0, 1] Probability each neuron will randomly fire\",\n",
       " \"refractory_period\": \"[<class 'int'>] Amount of time after spike neuron cannot fire.\",\n",
       " \"resting_mv\": \"[(<class 'float'>, <class 'int'>), default=0.0] Neuron resting voltage.\",\n",
       " \"spike_delay\": \"[<class 'int'>, default=0] [0, 10] Units of time after hitting threshold to fire.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_type = spikey.neuron.Neuron\n",
    "neuron_type.NECESSARY_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each part manages the whole set of such pieces, eg the Neuron part may contain 100+ neurons.\n",
    "neuron_config = {\n",
    "    'magnitude': 1.5,\n",
    "    'n_neurons': 4,\n",
    "    'neuron_pct_inhibitory': 0.,\n",
    "    'potential_decay': .25,\n",
    "    'prob_rand_fire': 0.,\n",
    "    'refractory_period': 1,\n",
    "    'resting_mv': 0.,\n",
    "    'firing_threshold': 2.,\n",
    "    'spike_delay': 0,\n",
    "}\n",
    "neuron = neuron_type(**neuron_config)\n",
    "neuron.reset()\n",
    "\n",
    "neuron.potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 1.5, 1.5, 1.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add potentials then see which fire\n",
    "neuron += np.full(neuron_config['n_neurons'],  10)\n",
    "fires = neuron()\n",
    "fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"n_inputs\": \"[<class 'int'>] Number input neurons, separate from body.\",\n",
       " \"n_neurons\": \"[<class 'int'>] Number of neurons in network.\",\n",
       " \"max_weight\": \"[(<class 'float'>, <class 'int'>)] Max synapse weight.\",\n",
       " \"matrix\": \"[<class 'numpy.ndarray'>] np.ma.array[n_inputs+n_neurons, n_neurons] Connections between individual inputs and neurons.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every piece of this simulator can be inhereted and extended or modified according to the user's needs.\n",
    "# Each object contains a base template (eg spikey.weight.template.Weight) that defines bare minimum expected functionality.\n",
    "from spikey.weight.template import Weight\n",
    "\n",
    "class CustomWeight(Weight):\n",
    "    NECESSARY_KEYS = Weight.extend_keys([\n",
    "        Key('matrix', 'np.ma.array[n_inputs+n_neurons, n_neurons] Connections between individual inputs and neurons.', type=np.ndarray)\n",
    "    ])\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._matrix = np.ma.copy(kwargs['matrix'])\n",
    "        assert self._matrix.shape == (self._n_inputs+self._n_neurons, self._n_neurons), \\\n",
    "            \"Incorrect weight shape!\"\n",
    "        self.clip()\n",
    "\n",
    "CustomWeight.NECESSARY_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = input_config['n_inputs']\n",
    "n_neurons = neuron_config['n_neurons']\n",
    "weight_config = {\n",
    "    \"n_inputs\": n_inputs,\n",
    "    \"n_neurons\": n_neurons,\n",
    "    \"max_weight\": 1,\n",
    "    'matrix': np.ones((n_inputs+n_neurons, n_neurons))\n",
    "}\n",
    "weight = CustomWeight(**weight_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A bare bones spiking network loop\n",
    "N_STEP = 10\n",
    "\n",
    "input.reset()\n",
    "neuron.reset()\n",
    "\n",
    "spike_log = np.empty((N_STEP, n_inputs + n_neurons))\n",
    "for s in range(N_STEP):\n",
    "    input.update(np.random.randint(4))\n",
    "\n",
    "    spikes = np.append(input(), neuron())\n",
    "\n",
    "    neuron += np.matmul(weight.matrix.T, spikes)\n",
    "\n",
    "    spike_log[s] = spikes\n",
    "\n",
    "plt.imshow(spike_log, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Spiking Neural Network\n",
    "\n",
    "Network is a neat interface for the many pieces that actually make up a spiking neural network.\n",
    "Simply pass it a list of part types with their configurations and it's ready to train.\n",
    "\n",
    "```none\n",
    "----------  -----------  ---------  -----\n",
    "| Neuron |  | Synapse |  | Input |  | ...\n",
    "----------  -----------  ---------  -----\n",
    "       \\         |         /\n",
    "         \\       |       /\n",
    "           -------------\n",
    "           |  Network  |\n",
    "           -------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"inputs\": \"[any] snn.input.Input\",\n",
       " \"neurons\": \"[any] snn.neuron.Neuron\",\n",
       " \"weights\": \"[any] snn.weight.Weight\",\n",
       " \"synapses\": \"[any] snn.synapse.Synapse\",\n",
       " \"readout\": \"[any] snn.readout.Readout\",\n",
       " \"modifiers\": \"[any, default=None] list of snn.modifier.Modifier\",\n",
       " \"rewarder\": \"[any] snn.reward.Reward\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar to individual piece's NECESSARY_KEYS, the Network has NECESSARY_PARTS\n",
    "network_type = spikey.network.RLNetwork\n",
    "network_type.NECESSARY_PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"n_inputs\": \"[<class 'int'>] Number input neurons, separate from body.\",\n",
      "\t\"n_outputs\": \"[<class 'int'>] Number of output neurons, a subset of body neurons.\",\n",
      "\t\"n_neurons\": \"[<class 'int'>] Number of neurons in the network.\",\n",
      "\t\"processing_time\": \"[<class 'int'>] Number of network timesteps per game timestep.\",\n",
      "\t\"magnitude\": \"[(<class 'float'>, <class 'int'>)] Multiplier to each 0, 1 spike value.\",\n",
      "\t\"input_firing_steps\": \"[<class 'int'>, default=-1] Number of network steps to fire for, -1 if all.\",\n",
      "\t\"input_pct_inhibitory\": \"[(<class 'float'>, <class 'int'>), default=0] Pct of inputs that are inhibitory\",\n",
      "\t\"state_spike_map\": \"[(<class 'dict'>, <class 'numpy.ndarray'>, <class 'object'>)] dict[tuple]->ndarray[processing_time, n_inputs, dtype=bool] State to fires map..\",\n",
      "\t\"firing_threshold\": \"[(<class 'float'>, <class 'int'>)] Neuron voltage threshold to fire.\",\n",
      "\t\"neuron_pct_inhibitory\": \"[(<class 'float'>, <class 'int'>), default=0] [0, 1] Percentage of inhibitory neurons.\",\n",
      "\t\"potential_decay\": \"[(<class 'float'>, <class 'int'>)] [0, 1] Percentage voltage loss on each tick.\",\n",
      "\t\"prob_rand_fire\": \"[(<class 'float'>, <class 'int'>), default=0]  [0, 1] Probability each neuron will randomly fire\",\n",
      "\t\"refractory_period\": \"[<class 'int'>] Amount of time after spike neuron cannot fire.\",\n",
      "\t\"resting_mv\": \"[(<class 'float'>, <class 'int'>), default=0.0] Neuron resting voltage.\",\n",
      "\t\"spike_delay\": \"[<class 'int'>, default=0] [0, 10] Units of time after hitting threshold to fire.\",\n",
      "\t\"max_weight\": \"[(<class 'float'>, <class 'int'>)] Max synapse weight.\",\n",
      "\t\"matrix\": \"[any] ndarray/func Matrix to use/generate.\",\n",
      "\t\"stdp_window\": \"[<class 'int'>] Time period that stdp will take effect.\",\n",
      "\t\"learning_rate\": \"[(<class 'float'>, <class 'int'>)] Scalar to trace updates.\",\n",
      "\t\"trace_decay\": \"[(<class 'float'>, <class 'int'>), default=1] Percent to decay trace by per timestep.\",\n",
      "\t\"n_actions\": \"[<class 'int'>] Number of groups to put neurons into. 0 pools means each neuron separate output.\",\n",
      "\t\"reward_mult\": \"[(<class 'float'>, <class 'int'>), default=1] Multiplier for reward, reward = 1 * reward_mult.\",\n",
      "\t\"punish_mult\": \"[(<class 'float'>, <class 'int'>), default=0] Multiplier for punishment, punish = -1 * punish_mult.\",\n",
      "\t\"expected_value\": \"[any] func(state)->action Expected action.\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parts = {\n",
    "    'inputs': spikey.input.StaticMap,\n",
    "    'neurons': spikey.neuron.Neuron,\n",
    "    'weights': spikey.weight.Manual,\n",
    "    'synapses': spikey.synapse.RLSTDP,\n",
    "    'readout': spikey.readout.NeuronRates,\n",
    "    'modifiers': None,\n",
    "    'rewarder': spikey.reward.MatchExpected,\n",
    "}\n",
    "\n",
    "network_type.list_keys(**parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_config = {\n",
    "    \"n_inputs\": 2,\n",
    "\t\"n_neurons\": 4,\n",
    "\t\"n_outputs\": 4,\n",
    "\t\"processing_time\": 10,\n",
    "\n",
    "\t\"magnitude\": 1,\n",
    "\t\"resting_mv\": 0,\n",
    "\t\"firing_threshold\": 2,\n",
    "\t\"spike_delay\": 0,\n",
    "\t\"refractory_period\": 1,\n",
    "\t\"potential_decay\": .25,\n",
    "\t\"prob_rand_fire\": 0,\n",
    "\t\"neuron_pct_inhibitory\": 0,\n",
    "\n",
    "\t\"learning_rate\": .01,\n",
    "\t\"stdp_window\": 20,\n",
    "\t\"trace_decay\": .25,\n",
    "\t\"max_weight\": 1,\n",
    "\t\"matrix\": np.random.uniform(size=(6, 4)),\n",
    "\t\"inh_weight_mask\": None,\n",
    "\n",
    "\t\"state_spike_map\": type('input_map', (object,), {'__getitem__': lambda s, x: np.array(x)})(),\n",
    "\t\"input_pct_inhibitory\": 0,\n",
    "\n",
    "    \"n_actions\": 0,\n",
    "\t\"output_range\": [0, 1],\n",
    "\n",
    "\t\"expected_value\": lambda state: np.sum(state) % 2,\n",
    "}\n",
    "\n",
    "network = network_type(**parts, **network_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative constructor approach, more readable when sharing to training loops and meta tools. Network template variables config and template parts have lower(lowest) priority than kwargs.\n",
    "class network_template(network_type):\n",
    "    keys = network_config\n",
    "    parts = parts\n",
    "\n",
    "network = network_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.2 0.1 0.1]\n",
      "[0.4 0.4 0.4 0.2]\n",
      "[0.  0.1 0.  0. ]\n",
      "[0.2 0.2 0.1 0.1]\n",
      "[0.4 0.4 0.4 0.2]\n",
      "[0.3 0.5 0.3 0.1]\n",
      "[0.3 0.4 0.3 0.2]\n",
      "[0.3 0.5 0.4 0.2]\n",
      "[0.  0.2 0.3 0. ]\n",
      "[0.2 0.3 0.2 0.1]\n"
     ]
    }
   ],
   "source": [
    "network.reset()\n",
    "\n",
    "for s in range(10):\n",
    "    output_rates = network.tick(np.random.randint(2, size=2))\n",
    "\n",
    "    print(output_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Games\n",
    "\n",
    "A game is the framework for how agents can interact with some environment. Spikey contains two classes of games: RL and MetaRL. RL is for training spiking neural networks and MetaRL is for genetic algorithms.\n",
    "\n",
    "All Spikey games are modelled after OpenAI gym environments, which can be converted to RL or MetaRL objects by the gym wrapper.\n",
    "\n",
    "It is important to use Spikey's pre-built games or build off of a template to ensure compatability with training loops and meta analysis tools.\n",
    "\n",
    "```python\n",
    "game_config = {\n",
    "    'n_inputs': 2,\n",
    "    'expected_value': lambda state: np.sum(state) % 2,\n",
    "}\n",
    "game = spikey.RL.Logic(**game_config)\n",
    "\n",
    "state = game.reset()\n",
    "for _ in range(10):\n",
    "    action = network.tick(state)\n",
    "\n",
    "    state, reward, done, info = game.step(action)\n",
    "    print(state, '\\t->', action)\n",
    "    if done:\n",
    "        break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"expected_value\": \"[any] func(state) Correct response of logic gate to specific state.\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_type = spikey.games.Logic\n",
    "game_type.NECESSARY_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AND': {'name': 'AND',\n",
       "  'expected_value': <function spikey.games.Logic.and_fn(state)>},\n",
       " 'OR': {'name': 'OR',\n",
       "  'expected_value': <function spikey.games.Logic.or_fn(state)>},\n",
       " 'XOR': {'name': 'XOR',\n",
       "  'expected_value': <function spikey.games.Logic.xor_fn(state)>}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Games may have a set of presets in game.PRESETS that set values for each key\n",
    "game_type.PRESETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization using preset only\n",
    "game = game_type(preset='XOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are able to use kwargs similar to network, which take precedent over the preset\n",
    "game_config = {\n",
    "    'n_inputs': 2,\n",
    "    'expected_value': lambda state: np.sum(state) % 2,\n",
    "}\n",
    "game = game_type(**game_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative method, hardcoded game_template.config has lower(lowest) priority than presets and kwargs.\n",
    "class game_template(game_type):\n",
    "    config = game_config\n",
    "\n",
    "game = game_template()\n",
    "_ = game.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, True) \t-> [0.  0.1 0.  0. ]\n",
      "(False, True) \t-> [0.2 0.2 0.1 0.1]\n",
      "(False, False) \t-> [0.3 0.3 0.3 0.1]\n",
      "(False, True) \t-> [0. 0. 0. 0.]\n",
      "(True, True) \t-> [0.2 0.2 0.1 0.1]\n",
      "(True, True) \t-> [0.4 0.4 0.4 0.2]\n",
      "(False, False) \t-> [0.3 0.5 0.3 0.1]\n",
      "(True, True) \t-> [0.  0.1 0.1 0.1]\n",
      "(False, True) \t-> [0.3 0.4 0.3 0.2]\n",
      "(False, True) \t-> [0.2 0.3 0.3 0.1]\n"
     ]
    }
   ],
   "source": [
    "state = game.reset()\n",
    "for _ in range(10):\n",
    "    action = network.tick(state)\n",
    "\n",
    "    state, reward, done, info = game.step(action)\n",
    "    print(state, '\\t->', action)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loops\n",
    "\n",
    "Spiking neural networks are trained by having them interact with some environment, then giving them feedback based on their performance via some reinforcement or supervision signal.\n",
    "In practice, the code that facilitates this process is called a training loop.\n",
    "By the way Spikey is organized, many distinct experiments can be executed with the exact same training loops.\n",
    "Therefore Spikey provides both pre-built and the ability for users to define their own training loops.\n",
    "\n",
    "Spikey uses [Ray Train, PyTorch version](https://docs.ray.io/en/latest/train/getting-started.html) for simple and distributed training.\n",
    "```none\n",
    "----------  -----------  ---------  -----\n",
    "| Neuron |  | Synapse |  | Input |  | ...\n",
    "----------  -----------  ---------  -----\n",
    "       \\         |         /\n",
    "         \\       |       /\n",
    "--------   -------------\n",
    "| Game |   |  Network  |\n",
    "--------   -------------\n",
    "   |            /\n",
    "   |           /\n",
    "-----------------\n",
    "| Training Loop |\n",
    "-----------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig, RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19052)\u001b[0m States: [[(False, True), (True, False), (False, False), (True, True), (False, True), (True, False), (True, True), (False, False), (False, False), (False, False)]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19052)\u001b[0m Actions: [[array([0.2, 0.2, 0.1, 0.1], dtype=float16), array([0.1, 0.3, 0.3, 0. ], dtype=float16), array([0., 0., 0., 0.], dtype=float16), array([0.3, 0.4, 0.3, 0.2], dtype=float16), array([0.3, 0.3, 0.2, 0.1], dtype=float16), array([0.1, 0.3, 0.4, 0.1], dtype=float16), array([0.4, 0.5, 0.4, 0.2], dtype=float16), array([0., 0., 0., 0.], dtype=float16), array([0., 0., 0., 0.], dtype=float16), array([0., 0., 0., 0.], dtype=float16)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19052)\u001b[0m 2022-12-11 09:00:48,162\tINFO config.py:87 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "2022-12-11 09:00:52,960\tERROR checkpoint_manager.py:327 -- Result dict has no key: training_iteration. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['trial_id', 'experiment_id', 'date', 'timestamp', 'pid', 'hostname', 'node_ip', 'done']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial TorchTrainer_595d3_00000 completed. Last result: \n"
     ]
    }
   ],
   "source": [
    "# Using pre-built, distributable training loop\n",
    "experiment_params = {\n",
    "    **network_config,\n",
    "    **parts,\n",
    "    **game_config,\n",
    "    \"n_episodes\": 1,\n",
    "    \"len_episode\": 10,\n",
    "}\n",
    "\n",
    "def train_func():\n",
    "    game = game_type(**experiment_params)\n",
    "    model = network_type(**experiment_params)\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    for epoch in range(experiment_params[\"n_episodes\"]):\n",
    "        model.reset()\n",
    "        state = game.reset()\n",
    "        state_next = None\n",
    "\n",
    "        states.append([])\n",
    "        actions.append([])\n",
    "        for s in range(experiment_params[\"len_episode\"]):\n",
    "            action = model.tick(state)\n",
    "            state_next, _, done, __ = game.step(action)\n",
    "            reward = model.reward(state, action, state_next)\n",
    "\n",
    "            states[-1].append(state)\n",
    "            actions[-1].append(action)\n",
    "\n",
    "            state = state_next\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    print(\"States:\", states)\n",
    "    print(\"Actions:\", actions)\n",
    "\n",
    "    return {}\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=ScalingConfig(num_workers=1),\n",
    "    run_config=RunConfig(verbose=0),\n",
    ")\n",
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True) \t-> [0.3 0.4 0.3 0.2]\n",
      "(False, False) \t-> [0.  0.  0.1 0. ]\n",
      "(True, False) \t-> [0.  0.2 0.2 0. ]\n",
      "(True, False) \t-> [0.  0.2 0.2 0. ]\n",
      "(True, True) \t-> [0.3 0.4 0.4 0.2]\n",
      "(True, False) \t-> [0.  0.3 0.2 0. ]\n",
      "(False, False) \t-> [0. 0. 0. 0.]\n",
      "(False, False) \t-> [0. 0. 0. 0.]\n",
      "(True, True) \t-> [0.3 0.4 0.3 0.2]\n",
      "(False, False) \t-> [0.1 0.  0.1 0. ]\n"
     ]
    }
   ],
   "source": [
    "# Fully custom training loop\n",
    "# NOTE: This method not recomended if you intend to use it in any meta analysis tools.\n",
    "game = game_template()\n",
    "network = network_template(game=game)\n",
    "\n",
    "for e in range(experiment_params[\"n_episodes\"]):\n",
    "    network.reset()\n",
    "    state = game.reset()\n",
    "\n",
    "    for s in range(experiment_params[\"len_episode\"]):\n",
    "        action = network.tick(state)\n",
    "\n",
    "        state_next, _, done, __ = game.step(action)\n",
    "\n",
    "        if hasattr(network, 'reward') and callable(getattr(network, 'reward')):\n",
    "            reward = network.reward(state, action, state_next)\n",
    "\n",
    "        print(state, '\\t->', action)\n",
    "\n",
    "        state = state_next\n",
    "\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward\n",
    "\n",
    "Along with the core SNN framework and training platform, Spikey contains meta analysis tools(eg genetic algorithm), a small vizualization set and pre-configured experiments in examples/ and `spikey.experiments`.\n",
    "\n",
    "Compared to deep neural networks, spiking neural networks are much closer to complex, dynamical systems than statistical tools. Interestingly they have the natural ability to reason about temporal information like series of events playing out over time. Internally they are able to encode information not only by the magnitudes of neuron fires but also into firing rates and temporal patterns! These attributes make SNNs ideal models for reinforcement learning, control tasks and more!\n",
    "\n",
    "Please share any difficulties or suggestions with Spikey or your spiking network related research in our issue tab so that we can help.\n",
    "\n",
    "Further introduction to SNNs,\n",
    "\n",
    "* [Paugam-Moisy H., Bohte S.(2012) Computing with Spiking Neuron Networks. In: Rozenberg G., Bäck T., Kok J.N. (eds) Handbook of Natural Computing. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-540-92910-9_10](https://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf)\n",
    "\n",
    "* [A. Grüning, S. Bohté(2014) Spiking Neural Networks: Principles and Challenges. ESAN.](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2014-13.pdf)\n",
    "\n",
    "* [What is a Spiking Neural Network? Spikey.](https://github.com/SpikeyCNS/spikey#spiking-neural-networks)\n",
    "\n",
    "Some SNN applications,\n",
    "\n",
    "* [Michael A. Farries and Adrienne L. Fairhall(2007)\n",
    "Reinforcement Learning With Modulated Spike Timing–Dependent Synaptic Plasticity.\n",
    "Journal of Neurophysiology 2007 98:6, 3648-3665.](https://journals.physiology.org/doi/pdf/10.1152/jn.00364.2007)\n",
    "\n",
    "* [Florian R(2007) Reinforcement Learning Through Modulation of\n",
    "Spike-Timing-Dependent Synaptic Plasticity. Neural Computation 19(6).\n",
    "https://doi.org/10.1162/neco.2007.19.6.1468](https://www.florian.io/papers/2007_Florian_Modulated_STDP.pdf)\n",
    "\n",
    "* [Stephen Chung and Robert Kozma(2020) Reinforcement Learning with Feedback-modulated TD-STDP. arXiv 2008.13044.](https://arxiv.org/abs/2008.13044)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
