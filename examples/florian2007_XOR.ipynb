{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1466fe8d14ba450eaad73bc0bfdd77c3",
   "display_name": "Python 3.7.6 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Replication of Florian 2007 XOR gate experiments.\n",
    "* Rate based input coding\n",
    "* Temporal pattern coding\n",
    "\n",
    "https://www.florian.io/papers/2007_Florian_Modulated_STDP.pdf\n",
    "\n",
    "Florian R (2007) Reinforcement Learning Through Modulation of Spike-Timing-Dependent Synaptic Plasticity. Neural Computation 19(6). https://doi.org/10.1162/neco.2007.19.6.1468"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spikey.snn import *\n",
    "from spikey.core import GenericLoop, RLCallback\n",
    "from spikey.RL import Logic\n",
    "from spikey.viz import print_rates\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_w_diffs(callback, training_params, layer_cutoff=None):\n",
    "    network = callback.network\n",
    "    info = callback.info\n",
    "\n",
    "    layer_cutoff = layer_cutoff or network._n_inputs\n",
    "\n",
    "    original_w = info['weights_original']\n",
    "    final_w = network.synapses.weights.matrix\n",
    "\n",
    "    print(f\"{np.sum(original_w[:, :layer_cutoff]):.0f} -> {np.sum(final_w[:, :layer_cutoff]):.0f}\")\n",
    "    print(f\"{np.sum(original_w[:, layer_cutoff:]):.0f} -> {np.sum(final_w[:, layer_cutoff:]):.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_success(callback, training_params):\n",
    "    info = callback.info\n",
    "\n",
    "    states = np.array(info['step_states']).reshape((-1, 2))\n",
    "    inrates = np.array(info['step_inrates']).reshape((-1))\n",
    "    sysrates = np.array(info['step_sysrates']).reshape((-1))\n",
    "    outrates = np.array(info['step_outrates']).reshape((-1))\n",
    "\n",
    "    HIGH = [[False, True], [True, False]]\n",
    "    LOW =  [[False, False], [True, True]]\n",
    "\n",
    "    relevant_timeframe = training_params['eval_steps'] // 4\n",
    "\n",
    "    high_rate = min([np.mean(outrates[np.all(states == state, axis=1)][-relevant_timeframe:]) for state in HIGH])\n",
    "    low_rate = max([np.mean(outrates[np.all(states == state, axis=1)][-relevant_timeframe:]) for state in LOW])\n",
    "\n",
    "    florian_win = high_rate > low_rate + .05\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(training_params['eval_steps']):\n",
    "        state = states[-i]\n",
    "        rate = outrates[-i]\n",
    "\n",
    "        if np.sum(state) % 2:\n",
    "            correct += int(rate > low_rate)\n",
    "        else:\n",
    "            correct += int(rate < high_rate)\n",
    "\n",
    "    florian_accuracy = correct / training_params['eval_steps']\n",
    "\n",
    "    print(f\"Florian - Win: {florian_win}, Accuracy: {florian_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_runtime(callback):\n",
    "    print(f\"{callback.results['total_time']:.2f}s\")"
   ]
  },
  {
   "source": [
    "## Rate Coding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 60\n",
    "N_NEURONS = 61\n",
    "N_OUTPUTS = 1\n",
    "PROCESSING_TIME = 500\n",
    "\n",
    "w_matrix = np.vstack((  # Feedforward w/ 1 hidden layer\n",
    "    np.hstack((\n",
    "        np.random.uniform(0, .2, (N_INPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((\n",
    "        np.zeros((N_NEURONS - N_OUTPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.random.uniform(0, .2, (N_NEURONS - N_OUTPUTS, N_OUTPUTS)))),\n",
    "    np.zeros((N_OUTPUTS, N_NEURONS)),\n",
    "))\n",
    "\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    parts = {\n",
    "        'inputs': input.RateMap,\n",
    "        'neurons': neuron.Neuron,\n",
    "        'synapses': synapse.RLSTDPET,\n",
    "        'weights': weight.Manual,\n",
    "        'readout': readout.Threshold,\n",
    "        'rewarder': reward.MatchExpected,\n",
    "    }\n",
    "    keys = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        'n_neurons': N_NEURONS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'matrix': w_matrix,\n",
    "\n",
    "        'input_pct_inhibitory': .5,\n",
    "        'neuron_pct_inhibitory': 0,\n",
    "        'magnitude': 1,\n",
    "        'firing_threshold': 16,\n",
    "        'refractory_period': 0,  # Gutig, Aharonov, Rotter, & Sompolinsky 2003\n",
    "        'prob_rand_fire': .15,  # Seemingly 0 in paper but >0 was needed\n",
    "        'potential_decay': .05,  # Decay constant Tau=20ms, lambda=e^(-t/T)\n",
    "        'trace_decay': .04,  # T_z = 25, lambda = e^(-1/T_z)\n",
    "        \"punish_mult\": 1,\n",
    "\n",
    "        'processing_time': PROCESSING_TIME,\n",
    "        'learning_rate': .625 / 25,  # gamma_0 = gamma / Tau_z\n",
    "        'max_weight': 5,\n",
    "        'stdp_window': 20,  # Tau_+ = Tau_- = 20ms\n",
    "        'action_threshold': 0,  # Makes network always output True\n",
    "\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "        'state_rate_map': [0, 40 / PROCESSING_TIME],   # 0hz in False groups, 40hz in True groups\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(False, False): 0.00 -> 0.15\n(False, True): 0.04 -> 0.15\n(True, False): 0.04 -> 0.16\n(True, True): 0.08 -> 0.14\n362 -> 362\n6 -> 6\nFlorian - Win: False, Accuracy: 0.56\n17.53s\n"
     ]
    }
   ],
   "source": [
    "# Control, without learning\n",
    "training_loop = GenericLoop(network_template, Logic(preset=\"XOR\"), measure_rates=True, **training_params)\n",
    "training_loop.reset(**{'learning_rate': 0, 'len_episode': 50})\n",
    "e_output = training_loop()\n",
    "\n",
    "callback = training_loop.callback\n",
    "print_rates(callback=callback)\n",
    "print_w_diffs(callback, training_params, layer_cutoff=None)\n",
    "print_success(callback, training_params)\n",
    "print_runtime(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(False, False): 0.00 -> 0.30\n(False, True): 0.04 -> 0.96\n(True, False): 0.04 -> 0.97\n(True, True): 0.08 -> 0.30\n362 -> 7510\n6 -> 296\nFlorian - Win: True, Accuracy: 1.0\n306.01s\n"
     ]
    }
   ],
   "source": [
    "# Real experiment\n",
    "training_loop = GenericLoop(network_template, Logic(preset=\"XOR\"), measure_rates=True, **training_params)\n",
    "e_output = training_loop()\n",
    "\n",
    "callback = training_loop.callback\n",
    "print_rates(callback=callback)\n",
    "print_w_diffs(callback, training_params, layer_cutoff=None)\n",
    "print_success(callback, training_params)\n",
    "print_runtime(callback)"
   ]
  },
  {
   "source": [
    "## Temporal Coding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 2\n",
    "N_NEURONS = 21\n",
    "N_OUTPUTS = 1\n",
    "PROCESSING_TIME = 500\n",
    "\n",
    "spike_train_map = {  # Static 100hz spike trains in response to stimulus\n",
    "    False: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= 50 * .0001),\n",
    "    True: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= 50 * .0001),\n",
    "}\n",
    "input_map = {\n",
    "    (A, B): np.hstack((spike_train_map[A], spike_train_map[B]))\n",
    "    for A in [False, True] for B in [False, True]\n",
    "}\n",
    "\n",
    "N_HIDDEN = N_NEURONS - N_OUTPUTS\n",
    "w_matrix = np.vstack((  # Feedforward w/ 1 hidden layer\n",
    "    np.hstack((np.random.uniform(0, .4, (N_INPUTS, N_HIDDEN)), np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((np.zeros((N_HIDDEN, N_HIDDEN)), np.random.uniform(0, .4, (N_HIDDEN, N_OUTPUTS)))),\n",
    "    np.zeros((N_OUTPUTS, N_NEURONS)),\n",
    "))\n",
    "\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    parts = {\n",
    "        'inputs': input.StaticMap,\n",
    "        'neurons': neuron.Neuron,\n",
    "        'synapses': synapse.RLSTDPET,\n",
    "        'weights': weight.Manual,\n",
    "        'readout': readout.Threshold,\n",
    "        'rewarder': reward.MatchExpected,\n",
    "    }\n",
    "    keys = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        'n_neurons': N_NEURONS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'matrix': w_matrix,\n",
    "\n",
    "        'input_pct_inhibitory': .5,\n",
    "        'neuron_pct_inhibitory': 0,\n",
    "        'magnitude': 1,\n",
    "        'firing_threshold': 16,\n",
    "        'refractory_period': 0,  # Gutig, Aharonov, Rotter, & Sompolinsky 2003\n",
    "        'prob_rand_fire': .15,\n",
    "        'potential_decay': .05,  # Decay constant Tau=20ms, lambda=e^(-t/T)\n",
    "        'trace_decay': .04,  # T_z = 25, lambda = e^(-1/T_z)\n",
    "        \"punish_mult\": 1,\n",
    "\n",
    "        'processing_time': PROCESSING_TIME,\n",
    "        'learning_rate': .25 / 25,  # gamma_0 = gamma / Tau_z\n",
    "        'max_weight': 5,\n",
    "        'stdp_window': 20,  # Tau_+ = Tau_- = 20ms\n",
    "        'action_threshold': 0,  # Makes network always output True\n",
    "\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "        'state_spike_map': input_map,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(False, False): 0.00 -> 0.15\n(False, True): 0.00 -> 0.15\n(True, False): 0.00 -> 0.15\n(True, True): 0.00 -> 0.14\n1 -> 1\n11 -> 11\nFlorian - Win: False, Accuracy: 0.5\n10.35s\n"
     ]
    }
   ],
   "source": [
    "# Control, without learning\n",
    "training_loop = GenericLoop(network_template, Logic(preset=\"XOR\"), measure_rates=True, **training_params)\n",
    "training_loop.reset(**{'learning_rate': 0, 'len_episode': 50})\n",
    "e_output = training_loop()\n",
    "\n",
    "callback = training_loop.callback\n",
    "print_rates(callback=callback)\n",
    "print_w_diffs(callback, training_params, layer_cutoff=None)\n",
    "print_success(callback, training_params)\n",
    "print_runtime(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(False, False): 0.00 -> 0.21\n(False, True): 0.00 -> 0.56\n(True, False): 0.00 -> 0.57\n(True, True): 0.00 -> 0.21\n1 -> 2\n11 -> 191\nFlorian - Win: True, Accuracy: 1.0\n166.01s\n"
     ]
    }
   ],
   "source": [
    "# Real experiment\n",
    "training_loop = GenericLoop(network_template, Logic(preset=\"XOR\"), measure_rates=True, **training_params)\n",
    "e_output = training_loop()\n",
    "\n",
    "callback = training_loop.callback\n",
    "print_rates(callback=callback)\n",
    "print_w_diffs(callback, training_params, layer_cutoff=None)\n",
    "print_success(callback, training_params)\n",
    "print_runtime(callback)"
   ]
  }
 ]
}