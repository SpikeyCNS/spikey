{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1466fe8d14ba450eaad73bc0bfdd77c3",
   "display_name": "Python 3.7.6 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Replication of Florian 2007 XOR gate experiments.\n",
    "* Rate based input coding\n",
    "* Temporal pattern coding\n",
    "\n",
    "https://www.florian.io/papers/2007_Florian_Modulated_STDP.pdf\n",
    "\n",
    "Florian R (2007) Reinforcement Learning Through Modulation of Spike-Timing-Dependent Synaptic Plasticity. Neural Computation 19(6). https://doi.org/10.1162/neco.2007.19.6.1468"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (network.py, line 149)",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\cole\\AppData\\Local\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3417\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-1-df05bb1dc26a>\"\u001b[0m, line \u001b[0;32m5\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from spikey.core import *\n",
      "  File \u001b[0;32m\"c:\\users\\cole\\desktop\\spikey\\spikey\\__init__.py\"\u001b[0m, line \u001b[0;32m8\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from spikey.snn import *  # import spikey.<part_type>.<part_class>\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\users\\cole\\desktop\\spikey\\spikey\\snn\\__init__.py\"\u001b[1;36m, line \u001b[1;32m13\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from spikey.snn.network import Network, RLNetwork, ContinuousRLNetwork\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\users\\cole\\desktop\\spikey\\spikey\\snn\\network.py\"\u001b[1;36m, line \u001b[1;32m149\u001b[0m\n\u001b[1;33m    int,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spikey.core import *\n",
    "from spikey.snn import *\n",
    "from spikey.RL import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rates(experiment_output, training_params):\n",
    "    _, __, ___, info = experiment_output\n",
    "\n",
    "    states = np.array(info['step_states'])\n",
    "    inrates = np.array(info['step_inrates'])\n",
    "    sysrates = np.array(info['step_sysrates'])\n",
    "    outrates = np.array(info['step_outrates'])\n",
    "\n",
    "    for state in [[False, False], [False, True], [True, False], [True, True]]:\n",
    "        mean_inrates = np.mean(inrates[np.all(states == state, axis=2)][-10:])\n",
    "\n",
    "        try:\n",
    "            mean_outrates = [np.mean(outrates[np.all(states == state, axis=2)][-10:, i]) for i in range(2)]\n",
    "        except IndexError:\n",
    "            mean_outrates = np.mean(outrates[np.all(states == state, axis=2)][-10:])\n",
    "\n",
    "        print(f\"{state}: {mean_inrates} -> {mean_outrates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_w_diffs(experiment_output, training_params, layer_cutoff=None):\n",
    "    network, __, ___, info = experiment_output\n",
    "\n",
    "    layer_cutoff = layer_cutoff or network._n_inputs\n",
    "\n",
    "    original_w = info['weights_original']\n",
    "    final_w = network.synapses.weights.matrix\n",
    "\n",
    "    print(f\"{np.sum(original_w[:, :layer_cutoff])} -> {np.sum(final_w[:, :layer_cutoff])}\")\n",
    "    print(f\"{np.sum(original_w[:, layer_cutoff:])} -> {np.sum(final_w[:, layer_cutoff:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_success(experiment_output, training_params):\n",
    "    _, __, ___, info = experiment_output\n",
    "\n",
    "    states = np.array(info['step_states']).reshape((-1, 2))\n",
    "    inrates = np.array(info['step_inrates']).reshape((-1))\n",
    "    sysrates = np.array(info['step_sysrates']).reshape((-1))\n",
    "    outrates = np.array(info['step_outrates']).reshape((-1))\n",
    "\n",
    "    HIGH = [[False, True], [True, False]]\n",
    "    LOW =  [[False, False], [True, True]]\n",
    "\n",
    "    relevant_timeframe = training_params['eval_steps'] // 4\n",
    "\n",
    "    high_rate = min([np.mean(outrates[np.all(states == state, axis=1)][-relevant_timeframe:]) for state in HIGH])\n",
    "    low_rate = max([np.mean(outrates[np.all(states == state, axis=1)][-relevant_timeframe:]) for state in LOW])\n",
    "\n",
    "    florian_win = high_rate > low_rate\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(training_params['eval_steps']):\n",
    "        state = states[-i]\n",
    "        rate = outrates[-i]\n",
    "\n",
    "        if np.sum(state) % 2:\n",
    "            correct += int(rate > low_rate)\n",
    "        else:\n",
    "            correct += int(rate < high_rate)\n",
    "\n",
    "    florian_accuracy = correct / training_params['eval_steps']\n",
    "\n",
    "    print(f\"Florian - Win: {florian_win}, Accuracy: {florian_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_runtime(callback):\n",
    "    print(f\"{callback.results['total_time']:.2f}s\")"
   ]
  },
  {
   "source": [
    "## Rate Coding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No training - Topology\n",
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 50,\n",
    "    'eval_steps': 50, \n",
    "}\n",
    "\n",
    "N_INPUTS = 60\n",
    "N_NEURONS = 61\n",
    "N_OUTPUTS = 1\n",
    "\n",
    "\n",
    "w_matrix = np.vstack((  # Fully connected, generated randomly over interval\n",
    "    np.hstack((\n",
    "        np.random.uniform(0, .2, (N_INPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((\n",
    "        np.zeros((N_NEURONS - N_OUTPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.random.uniform(0, .2, (N_NEURONS - N_OUTPUTS, N_OUTPUTS)))),\n",
    "    np.zeros((N_OUTPUTS, N_NEURONS)),\n",
    "))\n",
    "w_matrix = np.ma.array(np.float16(w_matrix), mask=(w_matrix == 0), fill_value=0)\n",
    "\n",
    "##\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    config = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'matrix': w_matrix,                  # v/\n",
    "        'n_neurons': N_NEURONS,       # v/\n",
    "        'input_pct_inhibitory': .5,   # v/\n",
    "        'neuron_pct_inhibitory': 0,          # v/\n",
    "        'processing_time': 500,       # v/ 500ms\n",
    "\n",
    "        'firing_threshold': 16,       # v/\n",
    "        'magnitude': 1,               # v/\n",
    "        'potential_decay': .05,       # v/ Decay constant Tau=20ms, lambda=e^(-t/T)\n",
    "        'prob_rand_fire': .05,        # Seemingly 0 in paper but this is critical to learning.\n",
    "        'refractory_period': 0,       # v/ Gutig, Aharonov, Rotter, & Sompolinsky 2003\n",
    "        'output_range': [0, 1],       # v/\n",
    "\n",
    "        'learning_rate': .0 / 25,   # v/ gamma_0 = gamma / Tau_z\n",
    "        'max_weight': 5,              # v/\n",
    "        'stdp_window': 20,            # v/ Tau_+ = Tau_- = 20ms\n",
    "        'trace_decay': .04,           # v/ T_z = 25, lambda = e^(-1/T_z)\n",
    "        'action_threshold': 0,        # v/ Irrelevant\n",
    "\n",
    "        'expected_value': lambda state: np.sum(state) % 2,\n",
    "        'continuous_rwd_action': lambda *a: None,\n",
    "        'state_rate_map': [0, .08],  # v/ 40hz = 40spikes/500ms\n",
    "    }\n",
    "    _template_parts = {\n",
    "        'inputs': input.RateMap,# Poisson\n",
    "        'neurons': neuron.Neuron,       # v/\n",
    "        'synapses': synapse.RLSTDPET,          # v/\n",
    "        'weights': weight.Manual,             # v/\n",
    "        'readout': readout.Threshold,         # v/\n",
    "        'rewarder': reward.MatchExpected,\n",
    "        'modifiers': None,\n",
    "    }\n",
    "\n",
    "class game_template(Logic):\n",
    "    config = Logic.PRESETS['XOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_CHECK_OUTPUT\n",
    "experiment = RLCallback(**training_params, logging=True, reduced=False, measure_rates=True)\n",
    "training_loop = GenericLoop(network_template, game_template, training_params)\n",
    "e_output = training_loop(callback=experiment)\n",
    "\n",
    "print_rates(e_output, training_params)\n",
    "print_w_diffs(e_output, training_params, layer_cutoff=None)\n",
    "print_success(e_output, training_params)\n",
    "print_runtime(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Default - WORKING\n",
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50, \n",
    "}\n",
    "\n",
    "N_INPUTS = 60\n",
    "N_NEURONS = 61\n",
    "N_OUTPUTS = 1\n",
    "\n",
    "\n",
    "w_matrix = np.vstack((  # Fully connected, generated randomly over interval\n",
    "    np.hstack((\n",
    "        np.random.uniform(0, .2, (N_INPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((\n",
    "        np.zeros((N_NEURONS - N_OUTPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.random.uniform(0, .2, (N_NEURONS - N_OUTPUTS, N_OUTPUTS)))),\n",
    "    np.zeros((N_OUTPUTS, N_NEURONS)),\n",
    "))\n",
    "w_matrix = np.ma.array(np.float16(w_matrix), mask=(w_matrix == 0), fill_value=0)\n",
    "\n",
    "# Timestep = 1ms\n",
    "# Trace suggestion multipliers - A_+ = 1, A_- = -1\n",
    "# Paper uses poisson input @ 40hz high\n",
    "# Paper uses inh weights not inh neurons\n",
    "# Paper seemingly has no random fires\n",
    "\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    config = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'matrix': w_matrix,                  # v/\n",
    "        'n_neurons': N_NEURONS,       # v/\n",
    "        'input_pct_inhibitory': .5,   # v/\n",
    "        'neuron_pct_inhibitory': 0,          # v/\n",
    "        'processing_time': 500,       # v/ 500ms\n",
    "\n",
    "        'firing_threshold': 16,       # v/\n",
    "        'magnitude': 1,               # v/\n",
    "        'potential_decay': .05,       # v/ Decay constant Tau=20ms, lambda=e^(-t/T)\n",
    "        'prob_rand_fire': .15,        # Seemingly 0 in paper but this is critical to learning.\n",
    "        'refractory_period': 0,       # v/ Gutig, Aharonov, Rotter, & Sompolinsky 2003\n",
    "        'output_range': [0, 1],       # v/\n",
    "\n",
    "        'learning_rate': .625 / 25,   # v/ gamma_0 = gamma / Tau_z\n",
    "        'max_weight': 5,              # v/\n",
    "        'stdp_window': 20,            # v/ Tau_+ = Tau_- = 20ms\n",
    "        'trace_decay': .04,           # v/ T_z = 25, lambda = e^(-1/T_z)\n",
    "\n",
    "        'expected_value': lambda state: np.sum(state) % 2,\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "\n",
    "        'action_threshold': 0,        # v/ Irrelevant\n",
    "        'state_rate_map': [0, .08],  # v/ 40hz = 40spikes/500ms\n",
    "    }\n",
    "    _template_parts = {\n",
    "        'inputs': input.RateMap,# Poisson\n",
    "        'neurons': neuron.Neuron,       # v/\n",
    "        'synapses': synapse.RLSTDPET,          # v/\n",
    "        'weights': weight.Manual,             # v/\n",
    "        'readout': readout.Threshold,         # v/\n",
    "        'rewarder': reward.MatchExpected,\n",
    "        'modifiers': None,\n",
    "    }\n",
    "\n",
    "class game_template(Logic):\n",
    "    config = Logic.PRESETS['XOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_CHECK_OUTPUT\n",
    "experiment = RLCallback(**training_params, logging=True, reduced=False, measure_rates=True)\n",
    "training_loop = GenericLoop(network_template, game_template, training_params)\n",
    "e_output = training_loop(callback=experiment)\n",
    "\n",
    "print_rates(e_output, training_params)\n",
    "print_w_diffs(e_output, training_params, layer_cutoff=None)\n",
    "print_success(e_output, training_params)\n",
    "print_runtime(experiment)"
   ]
  },
  {
   "source": [
    "## Temporal Coding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "N_INPUTS = 2\n",
    "N_NEURONS = 21\n",
    "N_OUTPUTS = 1\n",
    "\n",
    "PROCESSING_TIME = 500\n",
    "simple_map = {  # 100hz spike trains  - 50hz/500\n",
    "    False: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= .1),\n",
    "    True: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= .1),\n",
    "}\n",
    "\n",
    "input_map = {\n",
    "    (A, B): np.hstack((simple_map[A], simple_map[B]))\n",
    "    for A in [False, True] for B in [False, True]\n",
    "}\n",
    "N_HIDDEN = N_NEURONS - N_OUTPUTS\n",
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50,\n",
    "}\n",
    "matrix = np.vstack((\n",
    "    np.hstack((np.random.uniform(0, .2, (N_INPUTS, N_HIDDEN)), np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((np.zeros((N_HIDDEN, N_HIDDEN)), np.random.uniform(0, .2,(N_HIDDEN, N_OUTPUTS)))),\n",
    "    np.hstack((np.zeros((N_OUTPUTS, N_NEURONS)))),\n",
    "))\n",
    "matrix = np.ma.array(matrix, mask=(matrix == 0), fill_value=0)\n",
    "\n",
    "##\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    config = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'n_neurons': N_NEURONS,\n",
    "        'input_pct_inhibitory': .5,\n",
    "        'neuron_pct_inhibitory': 0,\n",
    "        'processing_time': PROCESSING_TIME,\n",
    "        'input_firing_steps': PROCESSING_TIME - 3,\n",
    "        'magnitude': 1,\n",
    "        'output_range': [0, 1],\n",
    "        'max_weight': 1,\n",
    "        'firing_threshold': 1,\n",
    "        'trace_decay': .05,\n",
    "        'potential_decay': .8,\n",
    "        'prob_rand_fire': .15,\n",
    "        'refractory_period': 5,\n",
    "        'stdp_window': 4,\n",
    "        'learning_rate': .25,\n",
    "        'action_threshold': .0,\n",
    "        'matrix': matrix,\n",
    "        'state_spike_map': input_map,\n",
    "        'expected_value': lambda state: np.sum(state) % 2,\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "    }\n",
    "    _template_parts = {\n",
    "        'inputs': input.StaticMap,\n",
    "        'neurons': neuron.Neuron,\n",
    "        'synapses': synapse.RLSTDPET,\n",
    "        'weights': weight.Manual,\n",
    "        'readout': readout.Threshold,\n",
    "        'rewarder': reward.MatchExpected,\n",
    "        'modifiers': None,\n",
    "    }\n",
    "\n",
    "class game_template(Logic):\n",
    "    config = Logic.PRESETS['XOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_CHECK_OUTPUT\n",
    "experiment = RLCallback(**training_params, logging=True, reduced=False, measure_rates=True)\n",
    "training_loop = GenericLoop(network_template, game_template, training_params)\n",
    "e_output = training_loop(callback=experiment)\n",
    "\n",
    "print_rates(e_output, training_params)\n",
    "print_w_diffs(e_output, training_params, layer_cutoff=None)\n",
    "print_success(e_output, training_params)\n",
    "print_runtime(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic w/ poisson process\n",
    "N_INPUTS = 2\n",
    "N_NEURONS = 21\n",
    "N_OUTPUTS = 1\n",
    "\n",
    "PROCESSING_TIME = 500\n",
    "simple_map = {  # 100hz spike trains\n",
    "    False: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= 50 * .0001),\n",
    "    True: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= 50 * .0001),\n",
    "}\n",
    "\n",
    "input_map = {\n",
    "    (A, B): np.hstack((simple_map[A], simple_map[B]))\n",
    "    for A in [False, True] for B in [False, True]\n",
    "}\n",
    "N_HIDDEN = N_NEURONS - N_OUTPUTS\n",
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50,\n",
    "}\n",
    "matrix = np.vstack((\n",
    "    np.hstack((np.random.uniform(0, .2, (N_INPUTS, N_HIDDEN)), np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((np.zeros((N_HIDDEN, N_HIDDEN)), np.random.uniform(0, .2,(N_HIDDEN, N_OUTPUTS)))),\n",
    "    np.hstack((np.zeros((N_OUTPUTS, N_NEURONS)))),\n",
    "))\n",
    "matrix = np.ma.array(matrix, mask=(matrix == 0), fill_value=0)\n",
    "\n",
    "##\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    config = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'n_neurons': N_NEURONS,\n",
    "        'input_pct_inhibitory': .5,\n",
    "        'neuron_pct_inhibitory': 0,\n",
    "        'processing_time': PROCESSING_TIME,\n",
    "        'input_firing_steps': PROCESSING_TIME - 3,\n",
    "        'magnitude': 1,\n",
    "        'output_range': [0, 1],\n",
    "        'max_weight': 1,\n",
    "        'firing_threshold': 1,\n",
    "        'trace_decay': .05,\n",
    "        'potential_decay': .8,\n",
    "        'prob_rand_fire': .15,\n",
    "        'refractory_period': 5,\n",
    "        'stdp_window': 4,\n",
    "        'learning_rate': .25,\n",
    "        'action_threshold': .0,\n",
    "        'matrix': matrix,\n",
    "        'state_spike_map': input_map,\n",
    "        'expected_value': lambda state: np.sum(state) % 2,\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "\n",
    "    }\n",
    "    _template_parts = {\n",
    "        'inputs': input.StaticMap,\n",
    "        'neurons': neuron.Neuron,\n",
    "        'synapses': synapse.RLSTDPET,\n",
    "        'weights': weight.Manual,\n",
    "        'readout': readout.Threshold,\n",
    "        'rewarder': reward.MatchExpected,\n",
    "        'modifiers': None,\n",
    "    }\n",
    "\n",
    "class game_template(Logic):\n",
    "    config = Logic.PRESETS['XOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_CHECK_OUTPUT\n",
    "experiment = RLCallback(**training_params, logging=True, reduced=False, measure_rates=True)\n",
    "training_loop = GenericLoop(network_template, game_template, training_params)\n",
    "e_output = training_loop(callback=experiment)\n",
    "\n",
    "print_rates(e_output, training_params)\n",
    "print_w_diffs(e_output, training_params, layer_cutoff=None)\n",
    "print_success(e_output, training_params)\n",
    "print_runtime(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For realism\n",
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50,\n",
    "}\n",
    "\n",
    "N_INPUTS = 2\n",
    "N_NEURONS = 21\n",
    "N_OUTPUTS = 1\n",
    "\n",
    "PROCESSING_TIME = 500\n",
    "simple_map = {  # 100hz spike trains  - 50hz/500\n",
    "    False: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= .1),\n",
    "    True: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= .1),\n",
    "}\n",
    "\n",
    "input_map = {\n",
    "    (A, B): np.hstack((simple_map[A], simple_map[B]))\n",
    "    for A in [False, True] for B in [False, True]\n",
    "}\n",
    "w_matrix = np.vstack((  # Fully connected, generated randomly over interval\n",
    "    np.hstack((\n",
    "        np.random.uniform(0, .4, (N_INPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((\n",
    "        np.zeros((N_NEURONS - N_OUTPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.random.uniform(0, .4, (N_NEURONS - N_OUTPUTS, N_OUTPUTS)))),\n",
    "    np.zeros((N_OUTPUTS, N_NEURONS)),\n",
    "))\n",
    "w_matrix = np.ma.array(np.float16(w_matrix), mask=(w_matrix == 0), fill_value=0)\n",
    "\n",
    "##\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    config = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'matrix': w_matrix,                  # v/\n",
    "        'n_neurons': N_NEURONS,       # v/\n",
    "        'input_pct_inhibitory': .5,   # v/\n",
    "        'neuron_pct_inhibitory': 0,          # v/\n",
    "        'processing_time': PROCESSING_TIME,# v/\n",
    "        'state_spike_map': input_map,\n",
    "\n",
    "        'firing_threshold': 16,       # v/\n",
    "        'magnitude': 1,               # v/\n",
    "        'potential_decay': .05,       # v/ Decay constant Tau=20ms, lambda=e^(-t/T)\n",
    "        'prob_rand_fire': .15,\n",
    "        'refractory_period': 0,       # v/ Gutig, Aharonov, Rotter, & Sompolinsky 2003\n",
    "        'output_range': [0, 1],       # v/\n",
    "\n",
    "        'learning_rate': .25 / 25,   # v/ gamma_0 = gamma / Tau_z\n",
    "        'max_weight': 5,              # v/\n",
    "        'stdp_window': 20,            # v/ Tau_+ = Tau_- = 20ms\n",
    "        'trace_decay': .04,           # v/ T_z = 25, lambda = e^(-1/T_z)\n",
    "        'expected_value': lambda state: np.sum(state) % 2,\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "        'action_threshold': 0,        # v/ Irrelevant\n",
    "    }\n",
    "\n",
    "    _template_parts = {\n",
    "        'inputs': input.StaticMap,\n",
    "        'neurons': neuron.Neuron,\n",
    "        'synapses': synapse.RLSTDPET,\n",
    "        'weights': weight.Manual,\n",
    "        'readout': readout.Threshold,\n",
    "        'rewarder': reward.MatchExpected,\n",
    "        'modifiers': None,\n",
    "    }\n",
    "\n",
    "class game_template(Logic):\n",
    "    config = Logic.PRESETS['XOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_CHECK_OUTPUT\n",
    "experiment = RLCallback(**training_params, logging=True, reduced=False, measure_rates=True)\n",
    "training_loop = GenericLoop(network_template, game_template, training_params)\n",
    "e_output = training_loop(callback=experiment)\n",
    "\n",
    "print_rates(e_output, training_params)\n",
    "print_w_diffs(e_output, training_params, layer_cutoff=None)\n",
    "print_success(e_output, training_params)\n",
    "print_runtime(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Realistic w/ poisson process - WORKING\n",
    "## For realism\n",
    "training_params = {\n",
    "    'n_episodes': 1,\n",
    "    'len_episode': 800,\n",
    "    'eval_steps': 50,\n",
    "}\n",
    "\n",
    "N_INPUTS = 2\n",
    "N_NEURONS = 21\n",
    "N_OUTPUTS = 1\n",
    "\n",
    "PROCESSING_TIME = 500\n",
    "simple_map = {  # 100hz spike trains\n",
    "    False: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= 50 * .0001),\n",
    "    True: np.int_(np.random.uniform(0, 1, (PROCESSING_TIME, N_INPUTS // 2)) <= 50 * .0001),\n",
    "}\n",
    "\n",
    "input_map = {\n",
    "    (A, B): np.hstack((simple_map[A], simple_map[B]))\n",
    "    for A in [False, True] for B in [False, True]\n",
    "}\n",
    "w_matrix = np.vstack((  # Fully connected, generated randomly over interval\n",
    "    np.hstack((\n",
    "        np.random.uniform(0, .4, (N_INPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.zeros((N_INPUTS, N_OUTPUTS)))),\n",
    "    np.hstack((\n",
    "        np.zeros((N_NEURONS - N_OUTPUTS, N_NEURONS - N_OUTPUTS)),\n",
    "        np.random.uniform(0, .4, (N_NEURONS - N_OUTPUTS, N_OUTPUTS)))),\n",
    "    np.zeros((N_OUTPUTS, N_NEURONS)),\n",
    "))\n",
    "w_matrix = np.ma.array(np.float16(w_matrix), mask=(w_matrix == 0), fill_value=0)\n",
    "\n",
    "##\n",
    "class network_template(ContinuousRLNetwork):\n",
    "    config = {\n",
    "        \"n_inputs\": N_INPUTS,\n",
    "        \"n_outputs\": N_OUTPUTS,\n",
    "        'matrix': w_matrix,                  # v/\n",
    "        'n_neurons': N_NEURONS,       # v/\n",
    "        'input_pct_inhibitory': .5,   # v/\n",
    "        'neuron_pct_inhibitory': 0,          # v/\n",
    "        'processing_time': PROCESSING_TIME,# v/\n",
    "        'state_spike_map': input_map,\n",
    "\n",
    "        'firing_threshold': 16,       # v/\n",
    "        'magnitude': 1,               # v/\n",
    "        'potential_decay': .05,       # v/ Decay constant Tau=20ms, lambda=e^(-t/T)\n",
    "        'prob_rand_fire': .15,\n",
    "\n",
    "        'refractory_period': 0,       # v/ Gutig, Aharonov, Rotter, & Sompolinsky 2003\n",
    "        'output_range': [0, 1],       # v/\n",
    "\n",
    "        'learning_rate': .25 / 25,   # v/ gamma_0 = gamma / Tau_z\n",
    "        'max_weight': 5,              # v/\n",
    "        'stdp_window': 20,            # v/ Tau_+ = Tau_- = 20ms\n",
    "        'trace_decay': .04,           # v/ T_z = 25, lambda = e^(-1/T_z)\n",
    "        'expected_value': lambda state: np.sum(state) % 2,\n",
    "        'continuous_rwd_action': lambda *a: True,\n",
    "        'action_threshold': 0,        # v/ Irrelevant\n",
    "    }\n",
    "\n",
    "    _template_parts = {\n",
    "        'inputs': input.StaticMap,\n",
    "        'neurons': neuron.Neuron,\n",
    "        'synapses': synapse.RLSTDPET,\n",
    "        'weights': weight.Manual,\n",
    "        'readout': readout.Threshold,\n",
    "        'rewarder': reward.MatchExpected,\n",
    "        'modifiers': None,\n",
    "    }\n",
    "\n",
    "class game_template(Logic):\n",
    "    config = Logic.PRESETS['XOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_CHECK_OUTPUT\n",
    "experiment = RLCallback(**training_params, logging=True, reduced=False, measure_rates=True)\n",
    "training_loop = GenericLoop(network_template, game_template, training_params)\n",
    "e_output = training_loop(callback=experiment)\n",
    "\n",
    "print_rates(e_output, training_params)\n",
    "print_w_diffs(e_output, training_params, layer_cutoff=None)\n",
    "print_success(e_output, training_params)\n",
    "print_runtime(experiment)"
   ]
  }
 ]
}